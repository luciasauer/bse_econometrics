{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e387ad68",
   "metadata": {},
   "source": [
    "# **TA #4 - Python version**\n",
    "\n",
    "## Foundation of Econometrics - DSDM 2025-2026\n",
    "\n",
    "**Lucia Sauer**\n",
    "\n",
    "**Contact:** [lucia.sauer@bse.eu](mailto:lucia.sauer@bse.eu)\n",
    "\n",
    "In this notebook we will review:\n",
    "\n",
    "1. Hypothesis testing with several restrictions\n",
    "2. Monte Carlo Simulations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea29573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", context = 'talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1a28e",
   "metadata": {},
   "source": [
    "Let's start by running the following regression:\n",
    "\n",
    "$$\\texttt{colGPA}_i​=\\beta_1​+\\beta_2\\texttt{​hsGPA}_i​+\\beta_3​\\texttt{job19}_i​\n",
    "+\\beta_4​\\texttt{job20}_i​\n",
    "+\\beta_5​\\texttt{skipped}_i​+\\beta_6​\\texttt{bgfriend}_i​+\\beta_7​\\texttt{alcohol}_i​ +\\varepsilon_i​ $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\texttt{colGPA}$: college GPA\n",
    "- $\\texttt{hsGPA}$: high school GPA\n",
    "- $\\texttt{job19}$: worked in 2019 (1=yes, 0=no)\n",
    "- $\\texttt{job20}$: worked in 2020 (1=yes, 0=no)\n",
    "- $\\texttt{skipped}$: \n",
    "- $\\texttt{bgfriend}$: has a boyfriend/girlfriend (1=yes, 0=no)\n",
    "- $\\texttt{alcohol}$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fece05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = woo.data('gpa1')\n",
    "\n",
    "model_full = sm.OLS.from_formula(\n",
    "    \"colGPA ~ hsGPA + job19 + job20 + skipped +  alcohol + bgfriend\", data=data\n",
    ").fit()\n",
    "print(model_full.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e2352",
   "metadata": {},
   "source": [
    "## **Global Hypothesis Testing**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo sin las dummies de año (restringido)\n",
    "data['intercept'] = 1  # Añadir una columna de intercepto\n",
    "model_restricted = sm.OLS.from_formula(\n",
    "    \"colGPA ~ intercept\", data=data\n",
    ").fit()\n",
    "\n",
    "# Modelo con las dummies (no restringido)\n",
    "model_unrestricted = sm.OLS.from_formula(\n",
    "    \"colGPA ~ hsGPA + job19 + job20 + skipped +  alcohol + bgfriend\", data=data\n",
    ").fit()\n",
    "\n",
    "#Compute manually the F-statistic\n",
    "RSSE = np.sum((data['colGPA'] - np.mean(data['colGPA']))**2)\n",
    "SSE = model_unrestricted.ssr\n",
    "F_manual = ((RSSE - SSE) / 6) / (SSE / (data.shape[0] - 7))\n",
    "print(f\"F-statistic (manual calculation): {F_manual:.4f}\")\n",
    "# Compare with the F-statistic from the unrestricted model\n",
    "print(f\"F-statistic (from model): {model_unrestricted.fvalue:.4f}\")\n",
    "\n",
    "print (f\"p-value (from model): {model_unrestricted.f_pvalue:.4f}\")\n",
    "\n",
    "#calculate p-value manually\n",
    "p_value_manual = 1 - stats.f.cdf(F_manual, 6, data.shape[0] - 7)\n",
    "print(f\"p-value (manual calculation): {p_value_manual:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ba472",
   "metadata": {},
   "source": [
    "## **Multiple Hypothesis Testing**\n",
    "---\n",
    "\n",
    "Test whether <code>job19</code> and <code>job20</code> are jointly statiscally significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1345f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo sin las dummies de año (restringido)\n",
    "data['intercept'] = 1  # Añadir una columna de intercepto\n",
    "model_restricted = sm.OLS.from_formula(\n",
    "    \"colGPA ~ hsGPA + skipped +  alcohol + bgfriend\", data=data\n",
    ").fit()\n",
    "\n",
    "# Modelo con las dummies (no restringido)\n",
    "model_unrestricted = sm.OLS.from_formula(\n",
    "    \"colGPA ~ hsGPA + job19 + job20 + skipped +  alcohol + bgfriend\", data=data\n",
    ").fit()\n",
    "\n",
    "#Compute manually the F-statistic\n",
    "RSSE = model_restricted.ssr\n",
    "SSE = model_unrestricted.ssr\n",
    "F_manual = ((RSSE - SSE) / 2) / (SSE / (data.shape[0] - 7))\n",
    "\n",
    "print(f\"F-statistic (manual calculation): {F_manual:.4f}\")\n",
    "#calculate p-value manually\n",
    "p_value_manual = 1 - stats.f.cdf(F_manual, 2, data.shape[0] - 7)\n",
    "print(f\"p-value (manual calculation): {p_value_manual:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe1321",
   "metadata": {},
   "source": [
    "## **Monte Carlo Simulation**\n",
    "\n",
    "---\n",
    "\n",
    "- Examine the *sampling distribution* of the estimator when:\n",
    "  \n",
    "    1. Increase the variance of the error term\n",
    "    2. Increase the degree of collinearity\n",
    "    3. Increase the sample size (consistency)\n",
    "\n",
    "$$\n",
    "y_i = 4 + 2x_{i2} + 2x_{i3} + \\varepsilon_i \n",
    "$$\n",
    "\n",
    "$$\\varepsilon_i \\,|\\, X_i \\sim \\text{i.i.d. } N(0,32)$$\n",
    "\n",
    "$$\n",
    "x_{i2} \\sim U[0,40], \\quad\n",
    "x_{i3} = x_{i2} + v_i, \\; v_i \\sim N(0, 16)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_betas(n=100, sigma_eps=4, sigma_v=4, reps=1000, conditional=False):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation of β₂ from y = 4 + 2x₂ + 2x₃ + ε.\n",
    "    \"\"\"\n",
    "    #add a seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "\n",
    "    betas = []\n",
    "    \n",
    "    # For conditional distribution: fix X once\n",
    "    if conditional:\n",
    "        x2_fixed = np.random.uniform(0, 40, n)\n",
    "        v_fixed  = np.random.normal(0, sigma_v, n)\n",
    "        x3_fixed = x2_fixed + v_fixed\n",
    "    \n",
    "    for _ in range(reps):\n",
    "        if conditional:\n",
    "            x2, x3 = x2_fixed, x3_fixed\n",
    "        else:\n",
    "            x2 = np.random.uniform(0, 40, n)\n",
    "            v  = np.random.normal(0, sigma_v, n)\n",
    "            x3 = x2 + v\n",
    "\n",
    "        eps = np.random.normal(0, sigma_eps, n)\n",
    "        y = 4 + 2*x2 + 2*x3 + eps\n",
    "\n",
    "        X = sm.add_constant(np.column_stack([x2, x3]))\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        betas.append(model.params[1])   # store β₂̂\n",
    "\n",
    "    return np.array(betas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_base = simulate_betas(n=1000, sigma_eps=32, sigma_v=16, reps=10000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "sns.kdeplot(betas_base, fill=True, alpha=0.5, color=\"purple\", label=\"Baseline\", edgecolor=\"black\", ax=ax)\n",
    "plt.axvline(2, color=\"black\", ls=\"--\", label=r\"True $\\beta_2$\")\n",
    "\n",
    "plt.title(r\"$\\hat{\\beta}_2$ sampling distribution\")\n",
    "plt.xlabel(r\"$\\hat{\\beta}_2$\")\n",
    "\n",
    "# Hide top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Set bottom and left spines to black\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "# Set tick color to black\n",
    "ax.tick_params(axis=\"x\", colors=\"black\")\n",
    "ax.tick_params(axis=\"y\", colors=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_base = simulate_betas(n=1000, sigma_eps=32, sigma_v=16, reps=10000)\n",
    "betas_low_sigma = simulate_betas(n=1000, sigma_eps=16, sigma_v=16, reps=10000)\n",
    "\n",
    "betas_high_sigma = simulate_betas(n=1000, sigma_eps=64, sigma_v=16, reps=10000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "sns.kdeplot(betas_low_sigma, fill=True, alpha=0.5, color = 'orange', label=r\"$\\sigma_{\\varepsilon}=16$\", edgecolor=\"black\", ax=ax)\n",
    "sns.kdeplot(betas_base, fill=True, alpha=0.5, color= 'purple',label=r\"$\\sigma_{\\varepsilon}=32$\", edgecolor=\"black\", ax=ax)\n",
    "sns.kdeplot(betas_high_sigma, fill=True, alpha=0.5, color = 'darkblue', label=r\"$\\sigma_{\\varepsilon}=64$\", edgecolor=\"black\", ax=ax)\n",
    "\n",
    "plt.axvline(2, color=\"black\", ls=\"--\", label=r\"True $\\beta_2$\")\n",
    "\n",
    "plt.title(r\"$\\hat{\\beta}_2$ sampling distribution\")\n",
    "plt.xlabel(r\"$\\hat{\\beta}_2$\")\n",
    "\n",
    "# Hide top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Set bottom and left spines to black\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "# Set tick color to black\n",
    "ax.tick_params(axis=\"x\", colors=\"black\")\n",
    "ax.tick_params(axis=\"y\", colors=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bd22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "betas_high_collinear = simulate_betas(n=1000, sigma_eps=32, sigma_v=32, reps=10000)\n",
    "betas_low_collinear = simulate_betas(n=1000, sigma_eps=32, sigma_v=8, reps=10000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "sns.kdeplot(betas_low_collinear, fill=True, alpha=0.5, color = 'orange', label=r\"$\\sigma_{v}=8$\", edgecolor=\"black\", ax=ax)\n",
    "sns.kdeplot(betas_base, fill=True, alpha=0.5, color= 'purple',label=r\"$\\sigma_{v}=16$\", edgecolor=\"black\", ax=ax)\n",
    "sns.kdeplot(betas_high_collinear, fill=True, alpha=0.5, color = 'darkblue', label=r\"$\\sigma_{v}=32$\", edgecolor=\"black\", ax=ax)\n",
    "\n",
    "plt.axvline(2, color=\"black\", ls=\"--\", label=r\"True $\\beta_2$\")\n",
    "\n",
    "plt.title(r\"$\\hat{\\beta}_2$ sampling distribution\")\n",
    "plt.xlabel(r\"$\\hat{\\beta}_2$\")\n",
    "\n",
    "# Hide top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Set bottom and left spines to black\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "# Set tick color to black\n",
    "ax.tick_params(axis=\"x\", colors=\"black\")\n",
    "ax.tick_params(axis=\"y\", colors=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3fb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "betas_large_sample = simulate_betas(n=10000)\n",
    "betas_small_sample = simulate_betas(n=100)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "sns.kdeplot(betas_large_sample, fill=True, alpha=0.5, color = 'orange', label=r\"$n=10000$\", edgecolor=\"black\", ax=ax)\n",
    "sns.kdeplot(betas_base, fill=True, alpha=0.5, color= 'purple',label=r\"$n=1000$\", edgecolor=\"black\", ax=ax)\n",
    "sns.kdeplot(betas_small_sample, fill=True, alpha=0.5, color= 'darkblue',label=r\"$n=100$\", edgecolor=\"black\", ax=ax)\n",
    "\n",
    "plt.axvline(2, color=\"black\", ls=\"--\", label=r\"True $\\beta_2$\")\n",
    "\n",
    "plt.title(r\"$\\hat{\\beta}_2$ sampling distribution\")\n",
    "plt.xlabel(r\"$\\hat{\\beta}_2$\")\n",
    "\n",
    "# Hide top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Set bottom and left spines to black\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "# Set tick color to black\n",
    "ax.tick_params(axis=\"x\", colors=\"black\")\n",
    "ax.tick_params(axis=\"y\", colors=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_base_cond = simulate_betas()\n",
    "betas_base_uncond = simulate_betas(conditional=True)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "\n",
    "sns.kdeplot(betas_base_cond, fill=True, alpha=0.5, color = 'orange', label=r\"$Conditioned$\", edgecolor=\"black\", ax=ax)\n",
    "sns.kdeplot(betas_base_uncond, fill=True, alpha=0.5, color= 'purple',label=r\"$Unconditioned$\", edgecolor=\"black\", ax=ax)\n",
    "\n",
    "plt.axvline(2, color=\"black\", ls=\"--\", label=r\"True $\\beta_2$\")\n",
    "\n",
    "plt.title(r\"$\\hat{\\beta}_2$ sampling distribution\")\n",
    "plt.xlabel(r\"$\\hat{\\beta}_2$\")\n",
    "\n",
    "# Hide top and right spines\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Set bottom and left spines to black\n",
    "ax.spines[\"bottom\"].set_color(\"black\")\n",
    "ax.spines[\"left\"].set_color(\"black\")\n",
    "# Set tick color to black\n",
    "ax.tick_params(axis=\"x\", colors=\"black\")\n",
    "ax.tick_params(axis=\"y\", colors=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455468a",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "| Scenario | What Happens to $Var(\\hat\\beta)$ | Intuition |\n",
    "|-----------|-----------------------------------|------------|\n",
    "| Higher error variance | ↑ | More noise → less precise |\n",
    "| Higher collinearity | ↑↑ | Redundant regressors → unstable estimates |\n",
    "| Larger sample n | ↓ | Consistency of OLS |\n",
    "| Conditional vs Unconditional | Similar centers, different spreads | Sources of randomness differ |\n",
    "\n",
    "Monte Carlo simulation helps visualize the small-sample behavior of estimators and verify theoretical properties.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse-econometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
