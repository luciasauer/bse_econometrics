---
title: "Econometrics"
subtitle: "<span class=\"subtitle-text\">TA Session 2</span>"
author: "Lucia Sauer"
institute: "<em>Barcelona School of Economics</em>"
date: "2025-10-03"
format:
  revealjs:
    df-print: paged
    #theme: metropolis
    transition: fade
    slide-number: true
    progress: true
    title-slide-attributes:
      data-background-position: "95% 90%"
      data-background-size: "100px"
editor:
  render-on-save: true

---

## Overview

- Conditional means
- OLS in matrix algebra
- OLS using R and Python preset functions
- Plotting observations and fitted lines
- Verify some numerical property

---

## Why These Topics?

::: {.callout-tip title = "Conditional means" icon=false}
Foundation of regression: OLS estimates the conditional mean of $Y$ given $X$.
:::

::: {.callout-tip title = "OLS in matrix algebra" icon=false}
Build intuition for how OLS works beyond formulas and preset functions.
:::

::: {.callout-tip title = "Numerical Conditions" icon=false}
Check core properties of OLS to validate results and understand residual behavior.
:::

---

## Conditional Mean


::: {.callout-note title="Conditional Mean" appearance="default" icon="false"}
**Population concept:**  
The *conditional mean* of $Y$ given $X=x$ is the expected value of $Y$ in the sub-population where $X=x$:  

$$E[Y|X=x]$$

**Sample estimate:**  
The *sample conditional mean* is the average of all observed $Y_i$ for which $X_i = x$:  
$$
\hat{E}[Y|X=x] = \frac{1}{N_x} \sum_{i: X_i = x} Y_i
$$
where $N_x$ is the number of observations with $X_i = x$.


ðŸ‘‰ The OLS estimator aims to model the *conditional mean function*, i.e., $E[Y|X]$, as a function of $X$.
:::

---

### Example: House Prices and Size

[Description dataset](http://fmwww.bc.edu/ec-p/data/wooldridge/datasets.list.html)

```{r, message=FALSE, warning=FALSE}
#| echo: true
#| eval: true
library(wooldridge)
library(dplyr)
df <- wooldridge::hprice1
# Sample of 8 observations
df[sample(nrow(df), 8), ]
```
---

### Compute Conditional Mean in R
```{r}
#| echo: true
#| eval: true
df_grouped <- df %>%
  group_by(bdrms) %>%
  summarise(mean_price = mean(price))
df_grouped
```

---



### Plot Conditional Mean in R
```{r}
#| echo: true
#| eval: false
library(ggplot2)
ggplot() +
  geom_point(data = df, aes(x = bdrms, y = price),
             color = 'orange', alpha = 0.6, size = 3) +
  geom_line(data = df_grouped, aes(x = bdrms, y = mean_price),
            color = 'orange', size = 1) +
  labs(title = expression(hat(E)[price ~ "|" ~ bdrms]),
       x = "Number of bedrooms",
       y = "Average house price")
```
```{r}
#| echo: false
#| eval: true
library(ggplot2)
#initialize the plot
ggplot() +
  # Scatter of raw data
  geom_point(data = df, aes(x = bdrms, y = price),
             color = "orange", size = 3, alpha = 0.6) +
  
  # Line plot of conditional means
  geom_line(data = df_grouped, aes(x = bdrms, y = mean_price),
            color = "orange", linewidth = 1) +
  
  # Titles and labels
  labs(
    title = expression(hat(E)*"["*price*"|"* bdrms*"]"),
    x = "Number of bedrooms",
    y = "House price"
  ) +
  
  # Styling similar to your Python example
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey80"),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold")
  )
```

---


## OLS in Matrix Algebra
Using our dataset, we can write the model as:
$$price\_i = \beta_1 + \beta_2 \cdot bdrms_i + \beta_3 \cdot sqrft_i + \beta_4 \cdot colonial_i + \varepsilon_i $$

We can express this model in matrix form as:

$${y} = {X} {\beta} + \varepsilon$$

where:
$$
\small
\begin{bmatrix}
price_1 \\
price_2 \\
\vdots \\
price_n
\end{bmatrix},
\quad
\begin{bmatrix}
1 & bdrms_1 & sqrft_1 & col_1 \\
1 & bdrms_2 & sqrft_2 & col_2 \\
\vdots & \vdots & \vdots \\
1 & bdrms_n & sqrft_n & col_n
\end{bmatrix},
\quad
\begin{bmatrix}
\beta_1 \\
\beta_2 \\
\beta_3 \\
\beta_4
\end{bmatrix},
\quad
\begin{bmatrix}
\varepsilon_1 \\
\varepsilon_2 \\
\vdots \\
\varepsilon_n
\end{bmatrix}
$$

---

### Exercise: OLS in Matrix Algebra
::: {.callout-warning title="Exercises" icon="false"}
1. Estimate the OLS coefficients using matrix algebra.
2. Compute the fitted values and OLS residuals.
3. Calculate the Sum of Squared Errors (SSE).
4. Compute the $R^2$ statistic.
:::

---

#### 1. Estimate the OLS Coefficients
Starting from the OLS objective function:

$$ \min_{{\tilde{\beta}}} {\tilde{\varepsilon}}'{\tilde{\varepsilon}} = \min_{{\tilde{\beta}}} ({y} - {X}{\tilde{\beta}})'({y} - {X}{\tilde{\beta}}) $$
The solution is given by:

<div style="text-align: center;"> <div style="border:2px solid #9d03c4ff; padding:10px; border-radius:8px; background-color:#f5e6ff; display:inline-block;"> $$\hat{\beta} = ({X}'{X})^{-1}{X}'{y}$$ </div> </div>


---

```{r}
#| echo: true
#| eval: true
df$intercept <- 1
X <- as.matrix(df[, c("intercept", "bdrms", "sqrft", "colonial")])
y <-df$price

#define X_tX and X_ty
X_tX <- t(X)%*%X
X_ty <- t(X)%*%y

#solve the system
beta_hat<- solve(X_tX)%*%X_ty
round(beta_hat, 2)
```

Fitted model:

$$
\small
\hat{price}_i = -21.55 + 12.49\cdot bdrms_i
+ 0.13\cdot sqrft_i + 13.08\cdot colonial_i
$$

where the dependent variable `price` is in **$1000s**.

---

#### 2. Compute the fitted values and OLS residuals.
 $${\hat{y}} = {X}\hat{\beta}$$ 


```{r}
#| echo: true
#| eval: true
# Fitted values
y_hat <- X %*% beta_hat
```

$$ \hat{\varepsilon} = {y} - {\hat{y}} $$
```{r}
#| echo: true
#| eval: true
# Residuals
epsilon_hat <- y - y_hat
```
::: {.callout-warning title="Units" icon="false"}
1. In what units are the fitted values ${\hat{y}}$?  
2. In what units are the residuals ${\hat{\varepsilon}}$?

:::

---

#### 3. Calculate the Sum of Squared Errors (SSE).

$$SSE = {\hat{\varepsilon}}'{\hat{\varepsilon}}$$

Note that this is exactly the same as:

$$ SSE = \sum_{i=1}^{n} (\hat{\varepsilon}_{i})^{2} = \sum_{i=1}^n (y_i - \hat{y}_i)^2$$

```{r}
#| echo: true
#| eval: true
#Sum of Squared Errors
SSE <- t(epsilon_hat) %*% epsilon_hat
round(SSE, 2)
```
::: {.callout-warning title = "SSE Units" icon=false}
**Note:** The SSE is in the squared units of the dependent variable (here, the price in 1000s of dollars).
:::

---

#### 4. Compute the $R^2$ statistic.

$$R^2 = 1 - \frac{SSE}{SST}$$

where
$$SST = ({y} - \bar{y}{1})'({y} - \bar{y}{1})$$

```{r}
#| echo: true
#| eval: true
# Total Sum of Squares
y_bar <- mean(y)
SST <- t(y - y_bar) %*% (y - y_bar)
r2 <- 1 - SSE/SST
round(r2, 4)
```
::: {.callout-warning title = "$R^2$ Units" icon=false}
**Note:** The $R^2$ is unit free, and tells us that about 64\% of the variation in house price is captured by the model.
:::
 
---

### 3. Python and R Preset Functions

::: {.callout-note title = "Preset Functions" icon=false}
All the operations we did in matrix algebra can be done using preset functions in Python and R.

- Python: `statsmodels` library, specifically the `OLS` class from `statsmodels.api`.
- R: `lm()` function.

:::

---

#### Code example in R

```{r}
#| echo: true
#| eval: true
#Estimate the model with lm function 
model <- lm(price ~ bdrms + sqrft + colonial, data = df)
beta_hat <- coef(model)
y_hat <- fitted(model)
epsilon_hat <- residuals(model)

sse <- sum(epsilon_hat^2)
r2 <- summary(model)$r.squared
cat("Coefficients (betas):\n", beta_hat)

cat("\nSSE:", round(sse, 2), "\n")
cat("R^2:", round(r2, 4), "\n")
```

---

### 4. Plotting Observations and Fitted Line

For a simple model of $K=2$, estimate the model and plot the observations and the fitted line.

$$ price_i = \beta_1 + \beta_2 \cdot sqrft_i + \epsilon_i $$

```{r}
#| echo: true
#| eval: true
#estimate the model
#first we need to estimate simple model
model <- lm(price ~ sqrft, data = df)
y_hat <- fitted(model)
beta_hat <- coef(model)
beta_hat
```
---

```{r}
#| echo: true
#| eval: false
#plot observations with scatter and fitted line
ggplot() + 
    #scatter with raw data
    geom_point(data = df, aes(x = sqrft, y = price),
    color = '#00518b') +

    geom_abline(intercept= beta_hat[1], slope = beta_hat[2],
    color = 'black', linewidth = 1) +
    #labels and styling
    labs(
        title = 'House size and price',
        x = 'sqrft',
        y='house price in 1000 usd'
    )

```

```{r}
#| echo: false
#| eval: true
eq <- paste0("price = ", round(beta_hat[1], 2), " + ", round(beta_hat[2], 2), " * sqrft")

ggplot(df, aes(x = sqrft, y = price)) +
  geom_point(color = "#00518b", size = 3, alpha = 0.6) +
  geom_abline(intercept = beta_hat[1], slope = beta_hat[2], color = "black", linewidth = 1) +
  annotate("text", x = min(df$sqrft), y = max(df$price), label = eq, hjust = 0, size = 5) +
  labs(title = "House Size and House Price", x = "House Size (Sqrft)", y = "House Price (1000 USD)") +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey80"),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold")
  )

```

---

### 5. Numerical Property of OLS

::: {.callout-note title = "Numerical Property of OLS" icon=false}
These properties are independent of the statistical assumptions, they are purely mathematical properties of the OLS estimator, that hold given a sample.

1. $$\sum_{i=1}^{n} \hat{\varepsilon_i} = 0$$

2. OLS is unitdependent, hence SSE is also unit independent.

:::

---

#### 1. Sum of residuals is zero
```{r}
#| echo: true
#| eval: true
epsilon_hat <- residuals(model)
round(sum(epsilon_hat),2)
```

Illustration:
```{r}
#| echo: false
#| eval: true
# 1) Residuals vs index (sum of residuals = 0)
# Create a data frame with index and residuals
residuals_df <- data.frame(
  index = 1:length(epsilon_hat),
  residuals = epsilon_hat
)
#inspect visually this property
ggplot(residuals_df, aes(x = index, y = residuals)) +
  geom_point(color = "darkgreen", size = 3, alpha = 0.6) +   # scatter points
  geom_hline(yintercept = 0, color = "black", linetype = "dashed") +  # horizontal line at 0
  labs(
    x = "Observation index",
    y = expression(hat(epsilon)),
    title = expression(hat(epsilon) ~ "vs Observation Index")
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey80"),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    plot.title = element_text(size = 16, face = "bold")
  )

```
---

#### 2. OLS unit dependent, hence SSE also unit dependent.

Our dependent variable is expressed in \$1000s, so let's scale it to actual dollars and see how the SSE changes.


```{r}
#| echo: true
#| eval: true
df$price <- df$price * 1000
model_dollars <- lm(price ~ sqrft, data = df)
beta_hat_dollars <- coef(model_dollars)
sse_dollars <- sum(residuals(model_dollars)^2)
cat("Coefficients in thousands of dollars:", round(beta_hat, 4), "\n")
cat("Coefficients in dollars:", round(beta_hat_dollars, 4), "\n")

cat("SSE in thousands of dollars:", round(sse, 2), "\n")
cat("SSE in dollars:", round(sse_dollars, 2), "\n")

```

